# üìã SP√âCIFICATIONS SYST√àME FINALES - DURUM AI Agent

## üéØ PRIORISATION FEATURES (Confirm√©e)

### PHASE 1 - MVP (Semaine 1-2) - MUST-HAVE

**A. Benchmarks Dynamiques** (Score: 10-6-10)
```
MUST-HAVE Phase 1:
‚úÖ Benchmarks 5 niveaux (CRITIQUE - Score 10)
‚è∏Ô∏è 30+ m√©triques (NICE-TO-HAVE - Score 6) ‚Üí Start avec 10-15 essentielles
‚úÖ Calcul automatique quotidien (CRITIQUE - Score 10)

Phase 1 Focus:
- M√©triques critiques: ROI, CPL, CPB, Close Rate, CTR, CPA
- 3 niveaux prioritaires: Global, Industry, Client History
- Calcul quotidien 9h AM
```

**C. Publishing Double Validation** (Score: 10-10-10-7)
```
MUST-HAVE Phase 1:
‚úÖ Workflow Airtable ‚Üí Client ‚Üí Vous ‚Üí Meta (Score 10)
‚úÖ Notifications Slack interactives (Score 10)
‚úÖ Rappels automatiques 24h (Score 10)
‚è∏Ô∏è 3 modes publication (Score 7) ‚Üí Start avec Auto/Manuel, Test = Phase 2

Phase 1 Focus:
- Client validation dans #client-X-validation
- Votre validation finale dans #durum-validation-finale
- Rappels 24h si pas de r√©ponse
- Publication Meta avec safeguards budget
```

**E. Analyse Multi-Niveaux** (Score: 10-6-10-10)
```
MUST-HAVE Phase 1:
‚úÖ Ads ‚Üí AdSets ‚Üí Campaigns (Score 10)
‚è∏Ô∏è Funnel Email/Booking (Score 6) ‚Üí Phase 2
‚úÖ Sales (Score 10)
‚úÖ Identification bottlenecks (Score 10)

Phase 1 Focus:
- Bottom-up analysis (ROI ‚Üí Ads)
- Bottleneck detection avec donn√©es r√©elles
- Integration GHL pour sales data
```

**F. Suggestions Automatiques** (Score: 9-10-7-10)
```
MUST-HAVE Phase 1:
‚úÖ Scale/Pause recommandations (Score 9)
‚úÖ Tests cr√©atifs sugg√©r√©s (Score 10)
‚è∏Ô∏è Optimisations funnel (Score 7) ‚Üí Phase 2
‚úÖ Approbation manuelle obligatoire (Score 10)

Phase 1 Focus:
- Max 10-20 suggestions/jour
- Confiance minimum 90%
- TOUJOURS 2-3 raisons data-driven
- Slack notifications group√©es
```

### PHASE 2 - Intelligence (Semaine 3-4)

**B. Analyse Cr√©ative Avanc√©e** (Score: 10-8-6-10)
```
‚úÖ D√©composition hooks/body/CTA/asset (Score 10)
‚úÖ Scores performance (Score 8)
‚è∏Ô∏è D√©tection fatigue (Score 6) ‚Üí Nice-to-have
‚úÖ Suggestions nouveaux angles (Score 10)
```

**D. Syst√®me Apprentissage IA** (Score: 9-7-10-10)
```
‚úÖ Pattern detection d√©cisions (Score 9)
‚è∏Ô∏è Hypothesis tracking (Score 7) ‚Üí Simple version Phase 1
‚úÖ Am√©lioration continue (Score 10)
‚úÖ Client knowledge base (Score 10)
```

---

## üìä DONN√âES & CONTEXTE

### √âtat Actuel

**Growth OS (Google Sheets)**:
- LOG_MASTER: 390 lignes (depuis 10 jan 2026)
- SPEND_MASTER: Depuis 10 jan 2026
- 02_metrics_period: ‚ùå NON EXISTANT ‚Üí √Ä cr√©er via AppScript
- Clients configur√©s: 0 ‚Üí √Ä cr√©er

**Airtable**:
- Tables ads/campaigns: ‚ùå NON ‚Üí √Ä cr√©er from scratch
- Historique: ‚ùå NON
- Clients: 6
- Ads historiques: 0 ‚Üí Import manuel/auto √† d√©cider

**Meta Ads**:
- API: ‚úÖ Configur√©
- Comptes: 6
- Historique: ‚úÖ Depuis cr√©ation comptes (plusieurs ann√©es)

**GHL**:
- Utilis√©: ‚úÖ OUI
- API: ‚úÖ Disponible
- Donn√©es email/SMS: ‚úÖ IMPORTANTES

### D√©cision Critique: Import Historique

**Option A**: Import automatique Meta ‚Üí Airtable
- R√©cup√©rer 6-12 mois historique via Meta API
- Populate tables ads/campaigns/adsets
- Enrich avec performance data
- **Avantage**: IA commence avec contexte
- **Temps**: 2-3 jours dev

**Option B**: Start fresh + Import manuel critique
- Cr√©er tables vides
- Vous importez manuellement top 10 winners pass√©s
- Syst√®me apprend au fur et √† mesure
- **Avantage**: Plus rapide d√©marrage
- **Temps**: 1 jour dev

**Recommandation**: Option A (import auto)
- IA beaucoup plus pr√©cise d√®s Jour 1
- Worth 2 jours extra dev

---

## üîÑ WORKFLOWS ACTUELS ‚Üí AUTOMATIS√âS

### Workflow 1: Cr√©ation Nouvelles Ads

**ACTUEL**:
```
1. Vous d√©cidez besoin nouvelles ads
2. Partner cr√©e copy dans Google Doc
3. Assets envoy√©s via Gmail
4. Review client dans Slack #validation
5. Approbation manuelle
6. Publication manuelle Meta
7. Suivi performance manuel (Meta + Sheets + partout)
```

**FUTUR (Automatis√©)**:
```
1. IA d√©tecte besoin refresh (fatigue detection)
   ‚Üí Suggestion: "Cr√©er 3 variations Hook X"
   ‚Üí Slack notification #durum-suggestions

2. Vous approuvez suggestion
   ‚Üí Status: "Approved - En cr√©ation"

3. Partner cr√©e copy dans Airtable directement
   ‚Üí Table: ads_drafts
   ‚Üí Status: "Draft - Pr√™t validation"

4. Assets upload√©s Airtable (ou lien)
   ‚Üí Validation structure automatique

5. IA envoie validation client Slack #client-X-validation
   ‚Üí Preview complet ad
   ‚Üí Boutons: ‚úÖ Approuver / üí¨ Commentaire

6. Client approuve
   ‚Üí Status: "Approuv√© Client"
   ‚Üí Notification #durum-validation-finale

7. Vous validation finale
   ‚Üí Status: "Approuv√© Final"
   ‚Üí Publication automatique Meta (1 min)

8. Suivi performance automatique
   ‚Üí Dashboard Looker Studio
   ‚Üí Alertes Slack si anomalies
   ‚Üí Suggestions optimization automatiques
```

**√âconomie temps**: 3-4h/semaine ‚Üí 30min/semaine

---

### Workflow 2: D√©cision Scaling

**ACTUEL**:
```
1. Vous regardez Meta manually
2. Identifiez adset qui performe (bon bookings, CPB, ROI)
3. D√©cidez scaler (ROI >3-5x)
4. V√©rifiez capacit√© vendeurs avec client
5. Scale manuellement Meta
6. Daily check performance
```

**FUTUR (Assist√© IA)**:
```
1. IA analyse quotidienne (9h AM)
   ‚Üí D√©tecte: AdSet "STACK_H:25/45 _QC" 
   ‚Üí ROI: 4.2x (benchmark: 2.8x)
   ‚Üí CPB: $95 (benchmark: $120)
   ‚Üí Bookings: 18/semaine (stable)

2. IA g√©n√®re suggestion
   ‚Üí "Scale AdSet +50% ($150 ‚Üí $225/jour)"
   ‚Üí Raison 1: ROI 4.2x (top 15% benchmark)
   ‚Üí Raison 2: CPB -21% vs benchmark (tr√®s efficient)
   ‚Üí Raison 3: Volume stable 3 semaines (pas fluke)
   ‚Üí Confiance: 92%

3. Notification Slack #durum-suggestions
   ‚Üí Vous voyez: donn√©es + graphes
   ‚Üí Check capacit√© vendeurs (manuel pour l'instant)

4. Vous approuvez
   ‚Üí IA scale automatiquement Meta
   ‚Üí Safeguard: Max budget journalier +50% (pas plus)
   ‚Üí Safeguard: Alerte si CPA >+25% dans 48h

5. Monitoring automatique
   ‚Üí Daily check performance
   ‚Üí Alerte si metrics d√©gradent
   ‚Üí Suggestion rollback si n√©cessaire

6. Vous recevez rapport 48h apr√®s scaling
   ‚Üí Performance vs pr√©dictions IA
   ‚Üí Validation hypoth√®se
   ‚Üí IA apprend de l'outcome
```

**√âconomie temps**: 2h/jour ‚Üí 15min/jour

---

## üîí CONTRAINTES & SAFEGUARDS

### Budget Safeguards (CRITIQUE)

```python
SAFEGUARDS_BUDGET = {
    # Limites par client
    'monthly_max_per_client': 100000,  # $100k/mois max
    
    # Limites par test/campagne
    'test_budget_max': 10000,  # 2x prix produit ($5k produit = $10k test max)
    
    # Scaling safeguards
    'max_scale_increment': 0.5,  # +50% max d'un coup
    'scale_cooldown_hours': 48,  # Attendre 48h entre scales
    
    # Budget blow-up protection
    'daily_overspend_alert': 1.2,  # Alerte si +20% budget pr√©vu
    'daily_overspend_pause': 1.5,  # PAUSE AUTO si +50% budget
    'hourly_check_overspend': True,  # Check chaque heure
    
    # Meta API safeguards
    'lifetime_budget_cap': True,  # TOUJOURS lifetime budget cap
    'bid_cap': True,  # Bid cap activ√©
    'cost_cap': True,  # Cost cap si disponible
}

# Sc√©nario B Protection
def check_budget_blowup():
    """
    V√©rifie budget blow-up CHAQUE HEURE
    """
    for adset in active_adsets:
        expected_spend = adset.budget_daily / 24 * hours_since_start
        actual_spend = get_meta_spend(adset.id)
        
        if actual_spend > expected_spend * 1.5:
            # PAUSE IMM√âDIAT
            pause_adset(adset.id)
            
            # ALERTE URGENTE
            slack.send_urgent_alert(
                channel='alerts-urgent',
                message=f"üö® BUDGET BLOW-UP DETECTED\n"
                        f"AdSet: {adset.name}\n"
                        f"Expected: ${expected_spend}\n"
                        f"Actual: ${actual_spend}\n"
                        f"‚Üí PAUSED AUTOMATICALLY"
            )
```

### Accuracy Safeguards (IA Suggestions)

```python
SUGGESTION_VALIDATION = {
    # Confiance minimum
    'min_confidence': 90,  # 90% minimum (vous avez demand√©)
    
    # Raisons data-driven
    'min_reasons': 2,  # Minimum 2 raisons
    'max_reasons': 4,  # Maximum 4 (√©viter overload)
    
    # Validation logique
    'check_conflicts': True,  # D√©tecte suggestions conflictuelles
    'check_sanity': True,     # Sanity check (ex: pas scale ad en perte)
}

# Sc√©nario C Protection
def validate_suggestion(suggestion):
    """
    Valide suggestion avant envoyer
    """
    # Check 1: Confidence
    if suggestion.confidence < 90:
        return False, "Confiance trop faible (<90%)"
    
    # Check 2: Raisons data-driven
    if len(suggestion.reasons) < 2:
        return False, "Pas assez de raisons"
    
    for reason in suggestion.reasons:
        if not has_data_support(reason):
            return False, f"Raison '{reason}' pas data-driven"
    
    # Check 3: Sanity check
    if suggestion.type == 'scale':
        if suggestion.current_roi < 1.0:
            return False, "ROI n√©gatif - absurde de scaler"
        
        if suggestion.current_cpa > suggestion.benchmark_cpa * 2:
            return False, "CPA 2x benchmark - absurde de scaler"
    
    # Check 4: Conflits
    active_suggestions = get_active_suggestions(suggestion.client_key)
    conflicts = detect_conflicts(suggestion, active_suggestions)
    
    if conflicts:
        return False, f"Conflit: {conflicts}"
    
    return True, "Valid"

# Gestion incertitude
def handle_uncertainty(confidence):
    """
    Si confiance <90%, expliquer pourquoi
    """
    if confidence < 90:
        return {
            'suggest': False,
            'message': f"Je ne sugg√®re pas (confiance {confidence}%). "
                      f"Raisons: [donn√©es insuffisantes / pattern pas clair / trop de variance]"
        }
```

### Data Quality Safeguards

```python
DATA_VALIDATION = {
    # D√©tection doublons
    'check_duplicates': True,
    'duplicate_threshold': 0.95,  # 95% similarit√© = doublon
    
    # Validation fra√Æcheur
    'max_data_age_hours': 24,  # Donn√©es >24h = alerte
    
    # Validation compl√©tude
    'min_data_completeness': 0.9,  # 90% champs remplis minimum
}

# Sc√©nario D Protection
def validate_data_quality(data_source):
    """
    Valide qualit√© donn√©es avant analyse
    """
    issues = []
    
    # Check duplicates
    duplicates = detect_duplicates(data_source)
    if duplicates:
        issues.append({
            'severity': 'CRITICAL',
            'issue': f"{len(duplicates)} doublons d√©tect√©s",
            'source': data_source.name,
            'action': 'PAUSE_ANALYSIS'
        })
    
    # Check freshness
    last_update = get_last_update(data_source)
    age_hours = (datetime.now() - last_update).hours
    
    if age_hours > 24:
        issues.append({
            'severity': 'WARNING',
            'issue': f"Donn√©es vieilles de {age_hours}h",
            'source': data_source.name,
            'action': 'ALERT_TEAM'
        })
    
    # Check completeness
    completeness = calculate_completeness(data_source)
    if completeness < 0.9:
        issues.append({
            'severity': 'HIGH',
            'issue': f"Donn√©es incompl√®tes ({completeness*100}%)",
            'source': data_source.name,
            'action': 'ALERT_TEAM'
        })
    
    if issues:
        # Alerter imm√©diatement
        for issue in issues:
            slack.send_alert(
                channel='alerts-urgent' if issue['severity'] == 'CRITICAL' else 'team-durum',
                message=f"‚ö†Ô∏è Data Quality Issue\n{json.dumps(issue, indent=2)}"
            )
        
        if any(i['severity'] == 'CRITICAL' for i in issues):
            # PAUSE analyses
            return False
    
    return True
```

### Conflict Resolution (Sc√©nario E)

```python
def resolve_suggestion_conflicts(suggestions):
    """
    R√©sout conflits entre suggestions
    Logique: Vue d'ensemble > Optimisations locales
    """
    conflicts = []
    
    # Exemple: Scale AdSet vs Pause Campaign parent
    for s1 in suggestions:
        for s2 in suggestions:
            if s1.id == s2.id:
                continue
            
            # Conflit: Scale AdSet + Pause Campaign parent
            if (s1.type == 'adset_scale' and 
                s2.type == 'campaign_pause' and
                s1.adset.campaign_id == s2.campaign_id):
                
                conflicts.append({
                    'suggestion1': s1,
                    'suggestion2': s2,
                    'type': 'scale_vs_pause_parent'
                })
    
    # R√©solution
    for conflict in conflicts:
        s1 = conflict['suggestion1']  # Scale adset
        s2 = conflict['suggestion2']  # Pause campaign
        
        # Analyser vue d'ensemble
        campaign = get_campaign(s2.campaign_id)
        all_adsets = get_campaign_adsets(campaign.id)
        
        winner_adsets = [a for a in all_adsets if a.roi > 3.0]
        loser_adsets = [a for a in all_adsets if a.roi < 1.5]
        
        if len(winner_adsets) == 1 and len(loser_adsets) >= 3:
            # 1 winner, 3+ losers ‚Üí Sc√©nario sp√©cial
            resolution = {
                'action': 'restructure_campaign',
                'steps': [
                    f"Pause {len(loser_adsets)} adsets sous-performants",
                    f"Garder winner AdSet {s1.adset.name}",
                    f"Continuer campaign avec winner seulement",
                    f"OU cr√©er nouvelle campaign d√©di√©e au winner"
                ],
                'reasoning': "1 mega-winner trouv√©, isoler pour scaler proprement"
            }
            
            # Cr√©er nouvelle suggestion composite
            return create_composite_suggestion(
                type='campaign_restructure',
                action=resolution['action'],
                steps=resolution['steps'],
                confidence=min(s1.confidence, s2.confidence) - 10,  # R√©duire conf car plus complexe
                reasoning=resolution['reasoning']
            )
        else:
            # Pas de winner clair ‚Üí Pause campaign correct
            return s2  # Garder suggestion pause campaign
```

---

## üì± COMMUNICATION & NOTIFICATIONS

### Style & Ton

**Ton**: D√©contract√© mais smart + Direct data-driven

**Exemples**:

**‚ùå Mauvais** (trop corporate):
```
"Notre algorithme a d√©tect√© une opportunit√© d'optimisation 
budg√©taire sur l'ensemble publicitaire STACK_H:25/45 en 
fonction des m√©triques de performance observ√©es."
```

**‚úÖ Bon** (votre style):
```
"üí° Opportunit√© Scale - STACK_H:25/45

ROI: 4.2x (top 15%)
CPB: $95 (-21% vs benchmark)
Volume: 18 bookings/sem (stable 3 sem)

‚Üí Scale +50% ($150 ‚Üí $225/jour)

Confiance: 92%
[Approuver] [Backlog] [Refuser]"
```

### Fr√©quence Notifications

```python
NOTIFICATION_SETTINGS = {
    # Max par jour
    'max_suggestions_per_day': 20,
    'max_priority_high': 10,
    'max_priority_medium': 15,
    
    # Grouping
    'group_by_hour': True,  # Grouper par heure
    'digest_time': '09:00',  # Digest quotidien 9h
    
    # Fen√™tre horaire
    'notification_window_start': '09:00',
    'notification_window_end': '14:00',
    'after_hours_action': 'backlog',  # Apr√®s 14h ‚Üí backlog lendemain
    
    # AI Credits optimization
    'batch_analysis': True,  # Analyser en batch vs real-time
    'analysis_frequency': 'daily',  # 1x/jour vs hourly
    'use_cache_aggressively': True,  # Cache r√©sultats 24h
}
```

**Sc√©nario 10h00 AM (en meeting)**:
- Suggestion arrive
- Va dans backlog Slack (thread)
- Vous regardez plus tard
- Syst√®me ne spam pas

### Format Notifications

**Morning Digest (9h AM)**:
```
üåÖ Daily Digest - 31 Jan 2025

üìä Hier Performance:
‚Ä¢ Spend: $4,250 (6 clients)
‚Ä¢ Leads: 47 (-8% vs avg)
‚Ä¢ Bookings: 12 (+15% üî•)
‚Ä¢ Sales: 3 (ROI: 3.8x)

üí° Suggestions Prioritaires (3):
1. [HIGH] Scale AdSet Avego STACK_H:25/45
2. [HIGH] Refresh Hooks Campagne Client2
3. [MED] Test nouveau angle Client3

üìã En Attente Validation (2):
‚Ä¢ Client Avego: 1 ad (24h)
‚Ä¢ Vous: 1 suggestion (backlog hier)

[Voir D√©tails] [Dashboard]
```

**Suggestion Individual (Temps r√©el)**:
```
üí° Suggestion #4521 - Scale Opportunity

Client: Avego
AdSet: STACK_H:25/45 _QC _FEED+

üìä Performance (7 jours):
ROI: 4.2x (vs 2.8x benchmark) ‚úÖ
CPB: $95 (vs $120 benchmark) ‚úÖ
Volume: 18 bookings/sem (stable) ‚úÖ

üéØ Action Propos√©e:
Scale budget +50%
$150/jour ‚Üí $225/jour

üí∞ Impact Attendu:
+~9 leads/semaine
CPB maintenu <$105
ROI attendu: 3.6-4.0x

üìà Raisons:
1. Top 15% performers (benchmark)
2. Stable 3 semaines (pas fluke)
3. Capacit√© vendeurs OK (v√©rifi√©)

Confiance: 92%

[‚úÖ Approuver] [‚è∏Ô∏è Backlog] [‚ùå Refuser]
```

---

## üïê PARCOURS JOURN√âE TYPE

### 9:00 AM - D√©marrage Syst√®me

```
Syst√®me d√©marre automatiquement:
1. Pull derni√®res donn√©es (LOG_MASTER, SPEND_MASTER, Meta API)
2. Valide qualit√© donn√©es (duplicates, freshness)
3. Calcule benchmarks (si pas √† jour)
4. Analyse performance veille/semaine/mois
```

### 9:15 AM - Analyse Compl√©t√©e

**Slack #durum-daily-digest**:
```
üåÖ Daily Digest Ready

üìä Hier (30 Jan):
[Graphique performance]
Spend: $4,250
ROI: 3.8x (‚Üë vs 3.5x avg)
Leads: 47 (‚Üì 8%)
Bookings: 12 (‚Üë 15%)

üí° 3 Suggestions Prioritaires
üìã 2 Items En Attente

[Voir Rapport Complet]
```

**Fichier Google Drive automatique**:
```
/DURUM/Reports/Daily/2025-01-31_Daily_Report.pdf

Contient:
- Performance tous clients
- Suggestions g√©n√©r√©es
- Alertes & anomalies
- Donn√©es d√©taill√©es
```

### 9:20 AM - Vous Ouvrez Notification

**Dans Slack, vous voyez**:
```
Thread avec 3 suggestions:

üí° #1 [HIGH] Scale AdSet Avego
[Preview complet avec data]
[Boutons action]

üí° #2 [HIGH] Refresh Hooks Client2
[Preview complet avec data]
[Boutons action]

üí° #3 [MED] Test Angle Client3
[Preview complet avec data]
[Boutons action]
```

### 9:25 AM - Vous Approuvez Suggestion #1

**Vous cliquez "‚úÖ Approuver"**:

1. Message Slack update:
```
üí° #1 [APPROVED] Scale AdSet Avego
‚úÖ Approuv√© par Alex - 09:25
üîÑ Ex√©cution en cours...
```

2. Airtable update:
```
Table: suggestions
Record #4521:
  status: "Approved" ‚Üí "Executing"
  approved_by: "Alex"
  approved_at: "2025-01-31 09:25:00"
```

3. Action Meta API:
```
Scale AdSet ID: 23849384938
Budget: $150 ‚Üí $225
Status: ACTIVE
```

### 9:30 AM - Action Ex√©cut√©e

**Slack confirmation**:
```
‚úÖ Suggestion #4521 - Ex√©cut√©e

AdSet Avego STACK_H:25/45
Budget scaled: $150 ‚Üí $225/jour

üîç Monitoring actif:
‚Ä¢ Check 24h: Performance stable?
‚Ä¢ Alert si CPA >+25%
‚Ä¢ Rapport 48h

[Voir Meta] [Dashboard]
```

**Airtable update**:
```
Table: suggestions
Record #4521:
  status: "Executing" ‚Üí "Executed"
  executed_at: "2025-01-31 09:30:15"
  meta_change_id: "act_123..."
  
Table: hypothesis_tracking (NEW):
  hypothesis: "Scale +50% ‚Üí +9 leads/sem, CPB <$105, ROI 3.6-4.0x"
  measurement_start: "2025-01-31"
  measurement_end: "2025-02-07" (7 jours)
```

### 10:00 AM - Nouvelle Suggestion (Vous en Meeting)

**Syst√®me d√©tecte**: Besoin refresh hooks Client2

**Action syst√®me**:
```
1. G√©n√®re suggestion #4522
2. Calcule confiance: 91%
3. Valide (confiance >90%, 3 raisons data-driven)
4. Envoie Slack #durum-suggestions
5. Ajoute table suggestions (status: "Pending")
```

**Vous**: En meeting, pas de probl√®me
- Notification reste dans Slack
- Vous verrez plus tard
- Pas de spam/urgence

### 5:00 PM - Fin Journ√©e

**Dashboard Looker Studio**:
```
DURUM - Sales & Pipeline Dashboard

üìä Aujourd'hui:
Calls: 12
Sales: 3 (25% close rate)
Revenue: $14,970
Pipeline: $87,400

üë• Reps Performance:
[Graphique par rep]
Rep 1: 2 sales (30% close)
Rep 2: 1 sale (20% close)
Rep 3: 0 sales (0% - besoin training?)

üìã Pipeline √âtat:
Applications: 47
Booked: 12
Showed: 9
Closed: 3

üö® Alertes:
‚Ä¢ Rep 3: 0% close rate (5 calls) ‚Üí Training?
‚Ä¢ Objection "prix" 60% calls ‚Üí Script update?

[Suggestions IA] [D√©tails]
```

**Slack Summary #durum-daily-summary** (Auto 17h):
```
üåÜ End of Day Summary

Aujourd'hui vous avez:
‚úÖ Approuv√© 1 suggestion (scale)
‚è∏Ô∏è Backlog 2 suggestions
üìä 3 nouvelles suggestions g√©n√©r√©es

Performance Ads:
$4,180 d√©pens√©
48 leads (+2 vs hier)
ROI: 3.9x (‚Üë)

Sales:
3 closes ($14,970)
Pipeline: $87,400

√Ä Demain! üöÄ
```

---

## üóÇÔ∏è TABLES AIRTABLE - STRUCTURE FINALE

### Tables Critiques Phase 1

**1. clients** (Existante - √Ä enrichir)
```
AJOUTER colonnes:
- industry
- main_offer
- ticket_price
- target_audience (JSON)
- slack_validation_channel
- slack_channel_id
- roi_target_min (default: 3.0)
- monthly_budget_max
```

**2. suggestions** (NOUVELLE)
```
suggestion_id, client_key, type, priority,
action_proposed, reason, hypothesis, confidence_score,
data_supporting (JSON), current_metrics (JSON),
expected_impact (JSON),
status, decided_by, decided_at,
executed_at, execution_status,
created_at, expires_at
```

**3. decisions** (NOUVELLE)
```
decision_id, suggestion_id, client_key,
decision (approved/refused/backlog),
decided_by, decided_at,
reason_approved, reason_refused,
modifications
```

**4. hypothesis_tracking** (NOUVELLE - Simplified Phase 1)
```
hypothesis_id, suggestion_id, client_key,
hypothesis_text, predicted_metrics (JSON),
executed_at, measurement_end_date,
actual_metrics (JSON), outcome,
variance (JSON)
```

**5. client_knowledge** (NOUVELLE)
```
client_key, industry, products (JSON),
target_audience (JSON), funnel_type,
winning_patterns (JSON), tested_angles (JSON),
preferences (JSON), updated_at
```

### Tables Phase 2

- global_learnings
- validation_logs
- decision_patterns
- feedback_loops
- etc.

---

## ‚ö° OPTIMISATION AI CREDITS

**Votre contrainte**: "Le moins de cr√©dits IA possible"

### Strat√©gie

```python
AI_OPTIMIZATION = {
    # Batch vs Real-time
    'analysis_mode': 'batch_daily',  # 1x/jour vs hourly
    'analysis_time': '09:00',        # 9h AM
    
    # Caching agressif
    'cache_benchmarks': 24,  # Cache 24h
    'cache_patterns': 168,   # Cache 7 jours
    'cache_suggestions': 1,  # Cache 1h (suggestions changent)
    
    # √âviter appels inutiles
    'min_data_change_pct': 5,  # Re-analyze seulement si >5% changement
    'skip_weekends': False,     # Analyser weekends? (√† d√©cider)
    
    # Utiliser models plus l√©gers quand possible
    'simple_tasks_model': 'haiku',    # Haiku pour tasks simples
    'complex_tasks_model': 'sonnet',  # Sonnet pour analyse complexe
}

# Estimation cr√©dits
# Avec batch daily + caching agressif:
# ~10-20 appels API/jour (vs 100+ si real-time)
# = ~$2-5/jour en cr√©dits (Anthropic)
```

---

## ‚úÖ R√âSUM√â D√âCISIONS FINALES

### Must-Have Phase 1 (2 semaines)

1. ‚úÖ Benchmarks dynamiques (3 niveaux: global, industry, client)
2. ‚úÖ Publishing double validation (Client ‚Üí Vous ‚Üí Meta)
3. ‚úÖ Analyse multi-niveaux (Ads ‚Üí Campaigns ‚Üí Sales)
4. ‚úÖ Suggestions automatiques (10-20/jour max, confiance >90%)
5. ‚úÖ Safeguards budget (blow-up protection critique)
6. ‚úÖ Data quality validation (anti-corruption)
7. ‚úÖ Slack notifications (digest 9h + real-time group√©)
8. ‚úÖ Dashboard sales/pipeline (Looker Studio)

### Nice-to-Have Phase 2

1. ‚è∏Ô∏è Analyse cr√©ative avanc√©e (fatigue, scores d√©taill√©s)
2. ‚è∏Ô∏è Syst√®me apprentissage complet (patterns, am√©lioration continue)
3. ‚è∏Ô∏è 3√®me mode publication (Test/Draft)
4. ‚è∏Ô∏è Optimisations funnel (email sequences, etc.)

### Contraintes Critiques

- ‚ùå JAMAIS m√©langer donn√©es clients dans communications
- ‚úÖ TOUJOURS validation manuelle (pas d'actions auto sans approval)
- ‚úÖ TOUJOURS 2-3 raisons data-driven par suggestion
- ‚úÖ Confiance minimum 90%
- ‚úÖ Budget safeguards (pause auto si overspend >50%)
- ‚úÖ Notifications fen√™tre 9h-14h (apr√®s = backlog)
- ‚úÖ Max 10-20 suggestions/jour
- ‚úÖ Optimiser cr√©dits IA (batch daily, caching)

### Import Historique

**D√©cision**: Import automatique Meta ‚Üí Airtable
- 6-12 mois historique
- Enrichir avec performance data
- IA d√©marre avec contexte
- +2-3 jours dev mais worth it

---

## üöÄ PR√äT POUR SPECS TECHNIQUES

Avec ces d√©cisions, je peux maintenant cr√©er:

1. **Architecture Technique D√©taill√©e**
   - Diagrammes s√©quence
   - Specs API compl√®tes
   - Structure donn√©es finalis√©e

2. **User Stories D√©taill√©es**
   - 10-15 sc√©narios complets
   - Crit√®res acceptation
   - Tests validation

3. **Roadmap D√©veloppement**
   - Semaine par semaine
   - Milestones clairs
   - D√©pendances identifi√©es

**Pr√™t pour √ßa?** Ou questions sur les d√©cisions ci-dessus?
